{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Expression of $ Z(\\alpha, \\beta)$\n",
    "\n",
    "The partition function $ Z(\\alpha, \\beta) $ ensures that $ p(x) $ is a valid probability distribution:\n",
    "\n",
    "$$\n",
    "Z(\\alpha, \\beta) = \\sum_{x \\in \\{0,1\\}^n} \\exp \\left( \\alpha \\sum_i x_i + \\beta \\sum_{i \\sim j} \\mathbf{1}_{x_i = x_j} \\right)\n",
    "$$\n",
    "\n",
    "where the sum runs over all possible configurations \\( x \\) of the system.\n",
    "\n",
    "### Why is $ Z(\\alpha, \\beta)$ difficult to compute?\n",
    "- The sum has **exponential complexity** in $ n $.\n",
    "- Computing it exactly requires summing over $ 2^n $ configurations, which is infeasible for large $ n $.\n",
    "- Instead, we use **sampling methods** (like Monte Carlo methods) to approximate it.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Likelihood and Log-Likelihood \n",
    "\n",
    "Let $ x^1, x^2, \\dots, x^n $ represent the **different observed configurations** of the Ising model, where each $ x^i $ is a vector of binary values representing the spin configurations.\n",
    "\n",
    "### Likelihood Function\n",
    "\n",
    "The **likelihood** is the **product of the probabilities** of these observed configurations given the model parameters $ \\alpha $ and $ \\beta $. For each configuration $ x^i $, the probability is given by the Ising model distribution:\n",
    "\n",
    "$$\n",
    "p(x^i \\mid \\alpha, \\beta) = \\frac{1}{Z(\\alpha, \\beta)} \\exp \\left( \\alpha \\sum_j x^i_j + \\beta \\sum_{j \\sim k} \\mathbf{1}_{x^i_j = x^i_k} \\right)\n",
    "$$\n",
    "\n",
    "The **likelihood** is the product of the probabilities for all observed configurations $ x^1, x^2, \\dots, x^n $:\n",
    "\n",
    "$$\n",
    "L(\\alpha, \\beta \\mid x^1, x^2, \\dots, x^n) = \\prod_{i=1}^{n} p(x^i \\mid \\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "Substituting the probability for each observation:\n",
    "\n",
    "$$\n",
    "L(\\alpha, \\beta \\mid x^1, x^2, \\dots, x^n) = \\prod_{i=1}^{n} \\frac{1}{Z(\\alpha, \\beta)} \\exp \\left( \\alpha \\sum_j x^i_j + \\beta \\sum_{j \\sim k} \\mathbf{1}_{x^i_j = x^i_k} \\right)\n",
    "$$\n",
    "\n",
    "### Log-Likelihood Function\n",
    "\n",
    "To simplify the computation, we take the **logarithm** of the likelihood to obtain the **log-likelihood**:\n",
    "\n",
    "$$\n",
    "\\log L(\\alpha, \\beta \\mid x^1, x^2, \\dots, x^n) = \\sum_{i=1}^{n} \\left( \\alpha \\sum_j x^i_j + \\beta \\sum_{j \\sim k} \\mathbf{1}_{x^i_j = x^i_k} \\right) - n \\log Z(\\alpha, \\beta)\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $ x^i_j $ refers to the $ j $-th element (spin) of the $ i $-th configuration vector $ x^i $.\n",
    "- The sum $ \\sum_j x^i_j $ is the total sum of spins in the $ i $-th configuration.\n",
    "- The sum $ \\sum_{j \\sim k} \\mathbf{1}_{x^i_j = x^i_k} $ counts the number of neighboring pairs of spins that are equal in the $ i $-th configuration.\n",
    "- $ Z(\\alpha, \\beta) $ is the partition function, which normalizes the distribution.\n",
    "\n",
    "---\n",
    "\n",
    "### Why is MLE difficult?\n",
    "- Computing $ Z(\\alpha, \\beta)$ is **intractable**.\n",
    "- Gradient-based optimization is challenging because computing gradients requires evaluating $ Z(\\alpha, \\beta)$.\n",
    "\n",
    "ðŸ‘‰ **Solution**: Instead of MLE, we use **Approximate Bayesian Computation (ABC)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from modules.ABC_reject import *\n",
    "from modules.Gibbs_sampler import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example run\n",
    "n = 10  # Grid size\n",
    "true_alpha, true_beta = 0.5, 0.8\n",
    "\n",
    "observed_grid = run_gibbs(n, true_alpha, true_alpha, steps=200)\n",
    "# observed_grid = ising_model(n, true_alpha, true_beta)\n",
    "obs_stats = sufficient_statistics(observed_grid)\n",
    "\n",
    "theta_samples = abc_reject(\n",
    "    obs_stats,\n",
    "    prior_alpha=(0, 2),\n",
    "    prior_beta=(0, 2),\n",
    "    n=n,\n",
    "    epsilon=0.5,\n",
    "    num_samples=1000,\n",
    ")\n",
    "print(\"Estimated alpha and beta:\", np.mean(theta_samples, axis=0))\n",
    "min_idx = np.argmin(theta_samples[:, 2])\n",
    "\n",
    "# Get the corresponding alpha and beta\n",
    "best_alpha, best_beta = theta_samples[min_idx, 0], theta_samples[min_idx, 1]\n",
    "\n",
    "print(\"nearest alpha and beta: \", (best_alpha, best_beta))\n",
    "print(\n",
    "    \" MSE :\",\n",
    "    0.5\n",
    "    * (\n",
    "        abs(0.5 - np.mean(theta_samples, axis=0)[0])\n",
    "        + abs(0.8 - np.mean(theta_samples, axis=0)[1])\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximate Bayesian Computation (ABC-Reject) for Ising Model\n",
    "\n",
    "## 1. Understanding the Sufficient Statistics\n",
    "\n",
    "In the Ising model, we define the **sufficient statistics**:\n",
    "\n",
    "$ S(x) = \\sum_i x_i, \\quad S_2(x) = \\sum_{i \\sim j} \\mathbf{1}_{x_i = x_j} $\n",
    "\n",
    "### What is $ S_2 $?\n",
    "- It represents the number of **neighboring pairs** where the spins are the same.\n",
    "- This is a key statistic because it captures the effect of the interaction parameter $ \\beta $, which favors alignment.\n",
    "\n",
    "\n",
    "\n",
    "## 2. Choosing the Distance Function\n",
    "\n",
    "Since ABC-Reject compares **simulated** and **observed** data, we define a distance function:\n",
    "\n",
    "$ d(S(x_{\\text{obs}}), S(x_{\\text{sim}})) = \\left| S(x_{\\text{obs}}) - S(x_{\\text{sim}}) \\right| + \\left| S_2(x_{\\text{obs}}) - S_2(x_{\\text{sim}}) \\right| $\n",
    "\n",
    "### Why this choice?\n",
    "- $ S(x) $ captures the **overall magnetization** (effect of $ \\alpha $).\n",
    "- $ S_2(x) $ captures **neighboring alignment** (effect of $ \\beta $).\n",
    "- The absolute difference ensures simple, interpretable comparison.\n",
    "- A **small threshold $ \\epsilon $** ensures we accept only close matches.\n",
    "\n",
    "\n",
    "\n",
    "## 3. ABC-Reject Algorithm Explained\n",
    "\n",
    "Since computing the likelihood function is intractable, **ABC** estimates parameters using simulation:\n",
    "\n",
    "1. **Generate observed data** $ x_{\\text{obs}} $ from the Ising model with **unknown** $ (\\alpha^*, \\beta^*) $.\n",
    "2. **For many iterations**:\n",
    "   - Sample $ (\\alpha, \\beta) $ from a **prior distribution**.\n",
    "   - Simulate $ x_{\\text{sim}} $ using the Ising model with $ (\\alpha, \\beta) $.\n",
    "   - Compute sufficient statistics $ S_2(x_{\\text{sim}}) $.\n",
    "   - **Accept** $ (\\alpha, \\beta) $ if the distance is **less than** $ \\epsilon $.\n",
    "3. The set of **accepted** $ (\\alpha, \\beta) $ values approximates their posterior distribution.\n",
    "\n",
    "\n",
    "\n",
    "## 4. Why Use ABC-Reject?\n",
    "\n",
    "- **No need for likelihood computation** (which is intractable due to $ Z(\\alpha, \\beta) $).\n",
    "- **Flexible**â€”can be applied to models with unknown normalizing constants.\n",
    "- **Drawback**: Inefficient for high-dimensional problems (many rejections).\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why are $ S(x) $ and $ S_2(x) $ sufficient statistics for the Ising Model?\n",
    "\n",
    "For the Ising model, the parameters we want to estimate are $ \\alpha $ and $ \\beta $, which affect the magnetization and the interactions between neighboring spins, respectively.\n",
    "\n",
    "- **Magnetization (summed spins):**\n",
    "\n",
    "  $$\n",
    "  S(x) = \\sum_i x_i\n",
    "  $$\n",
    "\n",
    "  This statistic captures the overall magnetic alignment (effect of $ \\alpha $) in the system.\n",
    "\n",
    "- **Neighbor interactions:**\n",
    "\n",
    "  $$\n",
    "  S_2(x) = \\sum_{i \\sim j} \\mathbf{1}_{x_i = x_j}\n",
    "  $$\n",
    "\n",
    "  This statistic counts how many neighboring spins are aligned (effect of $ \\beta $).\n",
    "\n",
    "\n",
    "### Intuition:\n",
    "\n",
    "- The **magnetization statistic** $ S(x) $ captures how many spins are aligned, which is directly influenced by $ \\alpha $ (external field).\n",
    "- The **interaction statistic** $ S_2(x) $ captures how many neighboring spins are aligned, which is directly influenced by $ \\beta $ (interaction strength).\n",
    "- Together, these statistics summarize the system in a way that no additional information (about individual spins or the precise configuration) is needed to estimate $ \\alpha $ and $ \\beta $.\n",
    "\n",
    "---\n",
    "\n",
    "### What Does \"Sufficiency\" Mean in Practice?\n",
    "\n",
    "- **In Ising model**: Knowing the total magnetization and the number of aligned neighbors in the system gives us everything we need to estimate the interaction strength $ \\beta $ and external field $ \\alpha $.\n",
    "- **For parameter estimation**: Once we have $ S(x) $ and $ S_2(x) $, we can use methods like Maximum Likelihood Estimation (MLE) or Approximate Bayesian Computation (ABC) to find the values of $ \\alpha $ and $ \\beta $ that best explain the observed data.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RESULTS for $\\alpha$ = 0.5 and $\\beta$ = 0.8 : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| $ n $ (System Size) | Number of Samples | $ \\epsilon $ (Tolerance) | $ \\alpha $ Estimate | $ \\beta $ Estimate | Time (s) | MSE |\n",
    "|---------------------|-------------------|--------------------------|---------------------|--------------------|----------|-----|\n",
    "| 10                  | 1000             | 0.001                      | 0.11                | 1.01               | 120       | 0.31 |\n",
    "| 20                  | 1000              | 0.001                     | 0.31                | 0.90               | 112       | 0.15 |\n",
    "| 30                  | 1000              | 0.001                     | 0.92                | 0.71               | 114       | 0.27 |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MC_project_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
